---
title: "2017 vs 2020 analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# -- OPTIONS --
pairsOnly <- FALSE # only include apps that exist in both datasets
librariesInsteadOfHosts <- FALSE # analyse libraries (exodus) instead of hosts

library(tidyverse)
library(jsonlite)
library(ineq)
library(scales)
library(vroom)
library(lubridate)
library(knitr)

#create function to calculate modal value
mode_func <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
knitr::opts_chunk$set(dev = 'svg')
```


# Initial wrangling
## Read in data
```{r}
# read in the company information
company_info_2017 <- fromJSON("data/company_data_list_2017.json") %>%
  as_tibble() %>%
  rename(company = owner_name) %>%
  select(company, country, root_parent) %>%
  mutate(country = str_to_upper(country)) %>%
  mutate(leaf_parent = ifelse(is.na(root_parent) | root_parent == "", company, root_parent)) %>% 
  mutate(crawl = "2017")

company_info_2020 <- fromJSON("data/company_data_list_2020.json") %>%
  as_tibble() %>%
  rename(company = owner_name) %>%
  select(company, country, root_parent) %>%
  mutate(country = str_to_upper(country)) %>%
  mutate(leaf_parent = ifelse(is.na(root_parent) | root_parent == "", company, root_parent)) %>% 
  mutate(crawl = "2020")

company_info <- company_info_2017 %>% 
  bind_rows(company_info_2020)

# read in our mapping of genres to super genres
genre_grouping <- read_csv("data/genre_grouping.csv") %>% select(-numApps)

#app_ids_2017 <- vroom("data/xray2017_appids.csv")
#apps_2017 <- vroom("data/2017_study/appInfo.csv", col_types = list(col_integer(), col_character(), col_character())) %>%
#  inner_join(app_ids_2017) %>%
#  distinct(app, .keep_all = TRUE) %>%
#  mutate(crawl = "2017")
apps_2017 <- read_csv("data/2017_study/appInfo.csv") %>%
#apps_2017 <- read_csv("data/2017_study/apps_exodus.csv") %>%
  distinct(app, .keep_all = TRUE) %>%
  select(-title, -version) %>% 
  mutate(crawl = "2017")
#apps_2020 <- read_csv("data/xray/apps_exodus.csv") %>%
apps_2020 <- read_csv("data/xray/apps_all.csv") %>%
  distinct(app, .keep_all = TRUE) %>%
  select(-title, -version) %>% 
  mutate(crawl = "2020")

if (librariesInsteadOfHosts) {
  hosts_2017 <- vroom("data_processed/2017_libraries_and_companies_long.csv") %>% 
    filter(id %in% apps_2017$id) %>% 
    mutate(crawl = "2017")  
  hosts_2020 <- vroom("data_processed/2020_libraries_and_companies_long.csv") %>%
    filter(id %in% apps_2020$id) %>%
    mutate(crawl = "2020")  
} else {
  hosts_2017 <- vroom("data_processed/2017_hosts_and_companies_long.csv") %>% 
    filter(id %in% apps_2017$id) %>% 
    mutate(crawl = "2017")  
  hosts_2020 <- vroom("data_processed/2020_hosts_and_companies_long.csv") %>%
    filter(id %in% apps_2020$id) %>%
    mutate(crawl = "2020")
}


if (pairsOnly) {
  # indetify common apps between 2017 and 2020
  common_apps <- apps_2017 %>%
    inner_join(apps_2020, by = "app")
  
  # restrict to common apps
  apps_2017 <- apps_2017 %>% 
   filter(app %in% common_apps$app)
  hosts_2017 <- hosts_2017%>%
   filter(id %in% apps_2017$id)
  apps_2020 <- apps_2020 %>% 
   filter(app %in% common_apps$app)
  hosts_2020 <- hosts_2020%>%
   filter(id %in% apps_2020$id)
}

apps <- apps_2017 %>% 
  bind_rows(apps_2020)

hosts <- hosts_2017 %>% 
  bind_rows(hosts_2020)

# Limit to popular tracker hosts: apply same cut-off to both crawls
hosts_prevalence <- hosts %>%
  group_by(crawl, hosts, company) %>%
  summarise(num_apps_present = n()) %>% 
  mutate(pct_apps_present = ifelse(crawl == "2017",
                                   (num_apps_present / nrow(apps_2017)*100),
                                   (num_apps_present / nrow(apps_2020)*100)))

hosts <- inner_join(hosts, hosts_prevalence) %>%
  mutate(company = ifelse(pct_apps_present >= 0.1,
                          company,
                          "unknown")) %>%
  select(-num_apps_present, -pct_apps_present)

tracker_hosts <- hosts %>% 
  filter(company != "unknown")

# Export for futher processing
tracker_hosts %>%
  group_by(company, crawl) %>%
  summarise(num_apps_present = n()) %>% 
  mutate(pct_apps_present = ifelse(crawl == "2017",
                                   (num_apps_present / nrow(apps_2017)*100),
                                   (num_apps_present / nrow(apps_2020)*100))) %>%
  write_csv2("data_processed/occurring_tracker_hosts.csv")

companies <- tracker_hosts %>%
  distinct(id, company, crawl) %>%
  left_join(company_info, by = c("company", "crawl")) %>%
  mutate(company = ifelse(is.na(root_parent), company, str_c(company, " (",root_parent,")"))) %>%
  select(-leaf_parent,-root_parent)

leaf_parents <- tracker_hosts %>%
  distinct(id, company, crawl) %>%
  left_join(company_info, by = c("company", "crawl")) %>%
  select(-company, -root_parent) %>%
  rename(company = leaf_parent) %>%
  distinct(crawl, id, company)

```

# Main analysis
## Number of hosts / domains that are associated with tracker companies
Summary stats

pct_more_than_x: x = 20 for hosts, x = 10 for library analysis

```{r}
# count tracker hosts
count_tracker_hosts <- tracker_hosts %>% 
  group_by(crawl, id) %>% 
  summarise(num_tracker_hosts = n())

# set count to 0 for apps that don't have any domains associated with tracker companies
apps_w_no_known_trackers <- apps %>%
  select(crawl, id) %>% 
  anti_join(count_tracker_hosts) %>% 
  mutate(num_tracker_hosts = 0)

# put together in common data frame
count_tracker_hosts <- count_tracker_hosts %>% 
  bind_rows(apps_w_no_known_trackers)

if (librariesInsteadOfHosts) {
  limit_hosts <- 10
} else {
  limit_hosts <- 20
}

# calculate summary statistics
count_tracker_hosts %>%
  group_by(crawl) %>% 
  summarise(num_apps = n(),
            median = median(num_tracker_hosts),
            Q1 = quantile(num_tracker_hosts, .25),
            Q3 = quantile(num_tracker_hosts, .75),
            IQR = IQR(num_tracker_hosts),
            min = min(num_tracker_hosts),
            max = max(num_tracker_hosts),
            mode = mode_func(num_tracker_hosts),
            mean = round(mean(num_tracker_hosts),1),
            SD = round(sd(num_tracker_hosts),2),
            num_more_than_x = sum(num_tracker_hosts > limit_hosts),
            pct_more_than_x = round((num_more_than_x / num_apps) * 100,2),
            no_refs = sum(num_tracker_hosts == 0),
            pct_none = round((no_refs / num_apps) * 100,2)) %>%
  select(-num_more_than_x, -no_refs) %>% 
  knitr::kable()

```

Gini coefficient
```{r}
count_tracker_hosts %>% 
  group_by(crawl) %>% 
  summarise("Gini coefficient" = ineq(num_tracker_hosts, type = 'Gini')) %>% 
  knitr::kable()

#plot the distribution in a histogram
#count_tracker_hosts %>%
#  #filter(num_tracker_hosts < 65) %>%
#  ggplot(aes(num_tracker_hosts, fill = crawl)) +
#  #geom_histogram(bins = 65) +
#  geom_density(alpha = 0.6) +
#  labs(x = "Number of tracker hosts per app"#, 
#       #title = "Number of tracker hosts in 2017 vs 2020 crawl"
#       ) #+
#  #scale_x_log10()

if (librariesInsteadOfHosts) {
  x <- "Number of tracker libraries per app"
  limit <- 20
} else {
  x <- "Number of tracker hosts per app"
  limit <- 65
}

count_tracker_hosts %>%
  filter(num_tracker_hosts < limit) %>%
  ggplot(aes(num_tracker_hosts, fill = crawl)) +
  #geom_density(position="identity", adjust = 3, alpha=0.5) +
  geom_histogram(binwidth = 1, position="identity", alpha=0.7, size=1.2) +
  theme(legend.position="top") +
  labs(x = x, y = "Number of apps")


```

### Create plot again for publication
```{r}
count_tracker_hosts %>%
  filter(num_tracker_hosts < limit) %>%
  ggplot(aes(num_tracker_hosts, fill = crawl)) +
  #geom_density(position="identity", adjust = 3, alpha=0.5) +
  geom_histogram(binwidth = 1, position="identity", alpha=0.7, size=1.2) +
  theme_minimal() +
  theme(legend.position="top") +
  labs(x = x, y = "Number of apps") +
  scale_y_continuous(labels = comma)

ggsave("figures/tracker_hosts_per_app.png")
```



## Most frequent hosts
### tracker hosts on our list
```{r}
#create short mapping from hosts to companies
hosts_to_company <- hosts %>%
  distinct(hosts, company, crawl)

#summary of tracker hosts
known_trackers_info <- tracker_hosts %>%
  group_by(hosts, crawl) %>% 
  summarise(num_apps_present = n()) %>% 
  mutate(pct_apps_present = ifelse(crawl == "2017",
                                   (num_apps_present / nrow(apps_2017)*100),
                                   (num_apps_present / nrow(apps_2020)*100))) %>% 
  left_join(hosts_to_company, by = c("hosts", "crawl")) %>% 
  left_join(company_info, by = c("company", "crawl")) %>%
  arrange(desc(num_apps_present))

top_trackers <- known_trackers_info %>% 
  group_by(crawl) %>% 
  arrange(desc(pct_apps_present)) %>% 
  slice(1:15) %>% 
  ungroup() %>%
  distinct(hosts)

known_trackers_info$hostscompany <- paste(known_trackers_info$hosts, " (", known_trackers_info$leaf_parent, ")", sep="")
 
known_trackers_info %>%
  filter(hosts %in% top_trackers$hosts) %>%
  ggplot() +
    geom_col(aes(x = reorder(hostscompany, pct_apps_present), y = pct_apps_present)) +
    facet_wrap(~crawl) +
    coord_flip() +
    labs(x = "Library (Root company)", y = "% apps present")

```

### Hosts not on our tracker list
```{r}
#create summary of 'unknown' hosts (i.e. not on our tracker list)
unknown_hosts_info <- hosts %>%
  filter(company == "unknown") %>%
  group_by(hosts, crawl) %>%
  summarise(num_apps_present = n()) %>% 
  mutate(pct_apps_present = ifelse(crawl == "2017",
                                   (num_apps_present / nrow(apps_2017)*100),
                                   (num_apps_present / nrow(apps_2020)*100))) %>% 
  arrange(desc(num_apps_present))

top_unknown <- unknown_hosts_info %>% 
  group_by(crawl) %>% 
  arrange(desc(pct_apps_present)) %>% 
  slice(1:30) %>% 
  ungroup() %>%
  distinct(hosts)
 
unknown_hosts_info %>%
  filter(hosts %in% top_unknown$hosts) %>%
  ggplot() +
    geom_col(aes(x = reorder(hosts, pct_apps_present), y = pct_apps_present)) +
    facet_wrap(~crawl) +
    coord_flip()

```


## Distinct companies per app
```{r}
get_count_tracker_companies <- function(companies){
  #count number of distinct companies in apps that include hosts that are on our tracker list
  company_counts_in_apps_w_known_trackers <- companies %>%
    group_by(crawl, id) %>%
    distinct(company) %>%
    summarise(num_companies = n())
  
  #set number of companies to 0 for the remaining apps
  apps_w_no_known_tracker_hosts <- apps %>%
    select(crawl, id) %>% 
    anti_join(company_counts_in_apps_w_known_trackers) %>% 
    mutate(num_companies = 0)
  
  # join the two
  count_tracker_companies <- company_counts_in_apps_w_known_trackers %>% 
    bind_rows(apps_w_no_known_tracker_hosts)
  
  return(count_tracker_companies)
}

count_tracker_companies <- get_count_tracker_companies(companies)

```

Calculate summary statistics
```{r}
#calculate summary statistics of distinct tracker companies per app
summarise_count_tracker_companies <- function(count_tracker_companies){
  return (count_tracker_companies %>%
  group_by(crawl) %>% 
  summarise(num_apps = n(),
            median = median(num_companies),
            Q1 = quantile(num_companies, .25),
            Q3 = quantile(num_companies, .75),
            mode = mode_func(num_companies),
            min = min(num_companies),
            max = max(num_companies),
            IQR = IQR(num_companies),
            mean_companies = round(mean(num_companies),1),
            SD = round(sd(num_companies),2),
            num_more_than_10 = sum(num_companies > 10),
            pct_more_than_10 = round((num_more_than_10 / num_apps) * 100,2),
            no_refs = sum(num_companies == 0),
            pct_none = round((no_refs / num_apps) * 100,2)) %>%
  select(-num_more_than_10, -no_refs) %>% 
  knitr::kable()) 
}

summarise_count_tracker_companies(count_tracker_companies)

```

Gini coefficient
```{r}

gini_tracker_companies <- function(count_tracker_companies){
  return (count_tracker_companies %>% 
    group_by(crawl) %>% 
    summarise("Gini coefficient" = ineq(num_companies, type = 'Gini')) %>% 
    knitr::kable())
}
  
  #plot the distribution in a boxplot
  #count_tracker_companies %>% 
  #  filter(num_companies < 30) %>%
  #  ggplot(aes(num_companies, fill = crawl)) +
  #    #geom_histogram(position = "dodge") +
  #    geom_boxplot()
  #    labs(x = "Number of distinct companies per app", y = "Number of apps")
  #    #scale_x_log10()

number_tracker_companies <- function(count_tracker_companies){
  return(count_tracker_companies %>%
            filter(num_companies < 20) %>%
            ggplot(aes(num_companies, fill = crawl)) +
            geom_histogram(binwidth = 1, position="identity", alpha=0.7, size=1.2) +
            theme(legend.position="top") +
            labs(x = "Number of distinct companies per app", y = "Number of apps") +
            scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
      )
}

gini_tracker_companies(count_tracker_companies)
number_tracker_companies(count_tracker_companies)

```

#### Recreate plot again for publication
```{r}
count_tracker_companies %>%
  filter(num_companies < 20) %>%
  ggplot(aes(num_companies, fill = crawl)) +
  geom_histogram(binwidth = 1, position="identity", alpha=0.7, size=1.2) +
  theme_minimal() +
  theme(legend.position="top") +
  labs(x = "Number of distinct companies per app", y = "Number of apps") +
  scale_y_continuous(labels = comma)
  
ggsave("figures/distinct_companies_per_app.png")
```



### Outliers (w/ more than 40 companies)
```{r}
# explore extreme outliers
outliers_tracker_companies <- function(count_tracker_companies, threshold){
  return(count_tracker_companies %>%
  filter(num_companies > threshold) %>%
  left_join(apps) %>%
  arrange(desc(num_companies)) %>% 
  DT::datatable())
}

outliers_tracker_companies(count_tracker_companies, 40)
```

## Distinct leaf parents per app
```{r}
count_tracker_leaf_parents <- get_count_tracker_companies(leaf_parents)

```

Calculate summary statistics
```{r}
summarise_count_tracker_companies(count_tracker_leaf_parents)

```

Gini coefficient

```{r}
gini_tracker_companies(count_tracker_leaf_parents)
number_tracker_companies(count_tracker_leaf_parents)

```

### Outliers (w/ more than 20 leaf companies)
```{r}
outliers_tracker_companies(count_tracker_leaf_parents, 20)

```

## Presence of specific tracker companies in apps
### Companies
```{r}
#calculate how many percent of apps each company (immediate owner) is present in
tracker_presence <- function(companies, limit = 20){
  prop_apps_w_tracking_company_refs <- companies %>%
  count(crawl, company) %>% 
  mutate(pct_of_apps = ifelse(crawl == "2017",
                                   (n / nrow(apps_2017)*100),
                                   (n / nrow(apps_2020)*100))) %>% 
  arrange(desc(n))

top_companies <- prop_apps_w_tracking_company_refs %>% 
  group_by(crawl) %>% 
  slice(1:limit) %>%
  ungroup() %>%
  distinct(company)

return(prop_apps_w_tracking_company_refs %>%
  filter(company %in% top_companies$company) %>%
  ggplot(aes(x = reorder(company, pct_of_apps), y = pct_of_apps)) +
    geom_col() +
    facet_wrap(~crawl) +
    coord_flip() +
    labs(x = "",
         y = ""))
}

tracker_presence(companies, 20)

```

### Leaf parents
```{r}
#calculate how many percent of apps each root company is present in
tracker_presence(leaf_parents, 15)
```


## Analyses by 'super genre'
### NUMBER OF DISTINCT TRACKER COMPANIES PER APP
```{r}
#first describe the number of distinct tracker companies per app for family apps
fam_count_company_refs <- count_tracker_companies %>%
  left_join(apps) %>%
  filter(!is.na(family_genre)) %>%
  mutate(super_genre = "Family")

fam_summary_company_count <- fam_count_company_refs %>%
  group_by(crawl) %>% 
  summarise(num_apps = n(),
            median = median(num_companies),
            Q1 = quantile(num_companies, .25),
            Q3 = quantile(num_companies, .75),
            mode = mode_func(num_companies),
            min = min(num_companies),
            max = max(num_companies),
            IQR = IQR(num_companies),
            mean_companies = round(mean(num_companies),1),
            SD = round(sd(num_companies),2),
            num_more_than_10 = sum(num_companies > 10),
            pct_more_than_10 = round((num_more_than_10 / num_apps) * 100,2),
            no_refs = sum(num_companies == 0),
            pct_none = round((no_refs / num_apps) * 100,2)) %>%
  select(-num_more_than_10, -no_refs) %>%
  mutate(super_genre = "Family")

```

analyse overall

```{r}
#then describe the number of tracker companies per app by super genre, and add a row with the description for family apps to the output
count_tracker_companies %>%
  left_join(apps) %>% 
  left_join(genre_grouping) %>% 
  group_by(crawl, super_genre) %>% 
  summarise(num_apps = n(),
            median = median(num_companies),
            Q1 = quantile(num_companies, .25),
            Q3 = quantile(num_companies, .75),
            mode = mode_func(num_companies),
            min = min(num_companies),
            max = max(num_companies),
            IQR = IQR(num_companies),
            mean_companies = round(mean(num_companies),1),
            SD = round(sd(num_companies),2),
            num_more_than_10 = sum(num_companies > 10),
            pct_more_than_10 = round((num_more_than_10 / num_apps) * 100,2),
            no_refs = sum(num_companies == 0),
            pct_none = round((no_refs / num_apps) * 100,2)) %>% 
  select(-num_more_than_10, -no_refs) %>% 
  bind_rows(fam_summary_company_count) %>%
  arrange(desc(median), desc(Q3), desc(pct_more_than_10), desc(crawl)) %>% 
  DT::datatable()


```

visualise number of companies

```{r}
#visualise this in a box plot
if (librariesInsteadOfHosts) {
  limit <- 12
  y <- "Number of tracker companies per app (libraries)"
} else {
  limit <- 22
  y <- "Number of tracker companies per app (hosts)"
}

count_tracker_companies %>%
  left_join(apps) %>%
  left_join(genre_grouping) %>% 
  bind_rows(fam_count_company_refs) %>%
  mutate(super_genre = factor(super_genre,
                              levels = c("Productivity & Tools","Communication & Social","Education","Health & Lifestyle","Music","Art & Photography","Games & Entertainment", "Family","News"), ordered = TRUE)) %>% 
  drop_na(super_genre) %>% 
  ggplot(aes(y = num_companies, x = super_genre, fill = crawl)) +
    geom_boxplot(varwidth = TRUE, outlier.shape = NA) + 
    labs(x = "", y = "Number of tracker companies per app") +
    scale_y_continuous(breaks = seq(0, 20, 4)) +
    coord_flip(ylim = c(0,limit)) +
    theme_minimal() +
    theme(legend.title = element_blank())

ggsave("figures/tracker_companies_per_app.png", height = 5, width = 5)

```


# TODO

# Recreating the python plot
## Prevalence plot
```{r}
prevalence_data <- read_csv("data/python_plot/prevalence.csv")

# turn into a tidy dataset
tidy_prevalence <- prevalence_data %>% 
  rename(company = X1,
         installs_2017 = min_installs,
         installs_2020 = min_installs_1) %>% 
  slice(3:n()) %>% 
  pivot_longer(cols = c(installs_2017, installs_2020)) %>% 
  rename(Year = name, ptc = value) %>% 
  mutate(Year = str_remove(Year, "installs_"))

# visualise
prevalence_plot <- tidy_prevalence %>% 
  group_by(company) %>% 
  mutate(sorting = max(ptc)) %>% 
  ggplot() +
    geom_col(aes(x = reorder(company, sorting), y = ptc, fill = Year), position = "dodge") +
    coord_flip() +
    theme_minimal() +
    theme(
      legend.position = c(.95, .35),
      legend.justification = c("right", "top"),
      legend.box.just = "right",
      legend.margin = margin(6, 6, 6, 6),
      legend.box.background = element_rect(color="lightgrey", size=0.3),
      text = element_text(size=12)
    ) +
    labs(x = "", y = "", title = "Prevalence (% of apps)")

ggsave(plot = prevalence_plot, "figures/prevalence_plot.png", height = 5, width = 5)
```


## Prominence plot
```{r}
prominence_data <- read_csv("data/python_plot/prominence.csv")

# turn into a tidy dataset
tidy_prominence <- prominence_data %>% 
  rename(company = X1,
         installs_2017 = min_installs,
         installs_2020 = min_installs_1) %>% 
  slice(3:n()) %>% 
  pivot_longer(cols = c(installs_2017, installs_2020)) %>% 
  rename(Year = name, ptc = value) %>% 
  mutate(Year = str_remove(Year, "installs_"))

# visualise
prominence_plot <- tidy_prominence %>% 
  group_by(company) %>% 
  mutate(sorting = max(ptc)) %>% 
  ggplot() +
    geom_col(aes(x = reorder(company, sorting), y = ptc, fill = Year), position = "dodge") +
    coord_flip() +
    theme_minimal() +
    theme(
      legend.position = c(.95, .35),
      legend.justification = c("right", "top"),
      legend.box.just = "right",
      legend.margin = margin(6, 6, 6, 6),
      legend.box.background = element_rect(color="lightgrey", size=0.3),
      text = element_text(size=12)
    ) +
    labs(x = "", y = "", title = "Prominence (% of app installs)")

ggsave(plot = prominence_plot, "figures/prominence_plot.png", height = 5, width = 5)
```

